{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from random import randint, randrange\n",
    "import sys\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import cv2\n",
    "print(\"CUDA available: {}\".format(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model architectures\n",
    "from models.DSCLRCN_OldContext import DSCLRCN\n",
    "from models.CoSADUV import CoSADUV\n",
    "from models.CoSADUV_NoTemporal import CoSADUV_NoTemporal\n",
    "\n",
    "# Prepare settings and get the datasets\n",
    "from util.data_utils import get_SALICON_datasets, get_video_datasets\n",
    "\n",
    "### Data options ###\n",
    "dataset_root_dir = \"Dataset/UAV123\"  # Dataset/[SALICON, UAV123]\n",
    "mean_image_name = (\n",
    "    \"mean_image.npy\"\n",
    ")  # Must be located at dataset_root_dir/mean_image_name\n",
    "img_size = (480, 640)  # height, width - original: 480, 640, reimplementation: 96, 128\n",
    "duration = 300  # Length of sequences loaded from each video, if a video dataset is used\n",
    "\n",
    "from util import loss_functions\n",
    "\n",
    "from util.solver import Solver\n",
    "\n",
    "### Training options ###\n",
    "\n",
    "# Batchsize: Determines how many images are processed before backpropagation is done\n",
    "batchsize = 20  # Recommended: 20.\n",
    "# Minibatchsize: Determines how many images are processed at a time on the GPU\n",
    "minibatchsize = 1  # Recommended: 4 for 480x640 for >12GB mem, 2 for <12GB mem.\n",
    "epoch_number = 5  # Recommended: 10 (epoch_number =~ batchsize/2)\n",
    "optim_str = \"SGD\"  # 'SGD' or 'Adam' Recommended: Adam\n",
    "optim_args = {\"lr\": 1e-2}  # 1e-2 if SGD, 1e-4 if Adam\n",
    "# Loss functions:\n",
    "# From loss_functions (use loss_functions.LOSS_FUNCTION_NAME)\n",
    "# NSS_loss\n",
    "# CE_MAE_loss\n",
    "# PCC_loss\n",
    "# KLDiv_loss\n",
    "loss_func = loss_functions.NSS_alt  # Recommended: NSS_loss\n",
    "test_loss_func = loss_functions.CE_MAE_loss\n",
    "\n",
    "### Prepare optimiser ###\n",
    "if batchsize % minibatchsize:\n",
    "    print(\n",
    "        \"Error, batchsize % minibatchsize must equal 0 ({} % {} != 0).\".format(\n",
    "            batchsize, minibatchsize\n",
    "        )\n",
    "    )\n",
    "    exit()\n",
    "num_minibatches = batchsize / minibatchsize\n",
    "\n",
    "# Scale the lr down as smaller minibatches are used\n",
    "optim_args[\"lr\"] /= num_minibatches\n",
    "\n",
    "optim = torch.optim.SGD if optim_str == \"SGD\" else torch.optim.Adam\n",
    "\n",
    "### Prepare datasets and loaders ###\n",
    "\n",
    "if \"SALICON\" in dataset_root_dir:\n",
    "    train_data, val_data, test_data, mean_image = get_SALICON_datasets(\n",
    "        dataset_root_dir, mean_image_name, img_size\n",
    "    )\n",
    "    train_loader = [\n",
    "        torch.utils.data.DataLoader(\n",
    "            train_data,\n",
    "            batch_size=minibatchsize,\n",
    "            shuffle=True,\n",
    "            num_workers=8,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "    ]\n",
    "    val_loader = [\n",
    "        torch.utils.data.DataLoader(\n",
    "            val_data,\n",
    "            batch_size=minibatchsize,\n",
    "            shuffle=True,\n",
    "            num_workers=8,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "    ]\n",
    "    # Load test loader using val_data as SALICON does not give GT for its test set\n",
    "    test_loader = [\n",
    "        torch.utils.data.DataLoader(\n",
    "            val_data,\n",
    "            batch_size=minibatchsize,\n",
    "            shuffle=True,\n",
    "            num_workers=8,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "    ]\n",
    "elif \"UAV123\" in dataset_root_dir:\n",
    "    train_loader, val_loader, test_loader, mean_image = get_video_datasets(\n",
    "        dataset_root_dir,\n",
    "        mean_image_name,\n",
    "        duration=duration,\n",
    "        img_size=img_size,\n",
    "        shuffle=False,\n",
    "        loader_settings={\n",
    "            \"batch_size\": minibatchsize,\n",
    "            \"num_workers\": 8,\n",
    "            \"pin_memory\": False,\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model\n",
    "train = False\n",
    "models = []\n",
    "model_names = []\n",
    "if train:\n",
    "    # Attempt to train a model using the original image sizes\n",
    "    model = CoSADUV(input_dim=img_size, local_feats_net=\"Seg\")\n",
    "\n",
    "    print(\"Starting train on model with settings:\")\n",
    "    print(\"### Dataset settings ###\")\n",
    "    print(\"Dataset: {}\".format(dataset_root_dir.split(\"/\")[-1]))\n",
    "    print(\"Image size: ({}h, {}w)\".format(img_size[0], img_size[1]))\n",
    "    print(\"Sequence duration: {}\".format(duration))\n",
    "    print(\"\")\n",
    "    print(\"### Training settings ###\")\n",
    "    print(\"Batch size: {}\".format(batchsize))\n",
    "    print(\"Minibatch size: {}\".format(minibatchsize))\n",
    "    print(\"Epochs: {}\".format(epoch_number))\n",
    "    print(\"\")\n",
    "    print(\"### Optimiser settings ###\")\n",
    "    print(\"Optimiser: {}\".format(optim_str))\n",
    "    print(\"Effective lr: {}\".format(str(optim_args[\"lr\"] * num_minibatches)))\n",
    "    print(\"Actual lr: {}\".format(str(optim_args[\"lr\"])))\n",
    "    print(\"Loss function: {}\".format(loss_func.__name__))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Create a solver with the options given above and appropriate location\n",
    "    solver = Solver(\n",
    "        optim=optim, optim_args=optim_args, loss_func=loss_func, location=location\n",
    "    )\n",
    "    # Start training\n",
    "    solver.train(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        num_epochs=epoch_number,\n",
    "        num_minibatches=num_minibatches,\n",
    "        log_nth=50,\n",
    "        filename_args={\n",
    "            \"batchsize\": batchsize,\n",
    "            \"epoch_number\": epoch_number,\n",
    "            \"optim\": optim_str,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    models.append(model)\n",
    "    model_names.append(\n",
    "        \"model_{}_{}_batch{}_epoch{}\".format(type(model).__name__, loss_func.__name__, batchsize, epoch_number)\n",
    "    )\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model:\n",
    "if train:\n",
    "    model.save(\n",
    "        \"trained_models/model_{}_{}_batch{}_epoch{}\".format(\n",
    "            type(model).__name__, loss_func.__name__, batchsize, epoch_number\n",
    "        )\n",
    "    )\n",
    "    with open(\n",
    "        \"trained_models/solver_{}_{}_batch{}_epoch{}.pkl\".format(\n",
    "            type(model).__name__, loss_func.__name__, batchsize, epoch_number\n",
    "        ),\n",
    "        \"wb\",\n",
    "    ) as outf:\n",
    "        pickle.dump(solver, outf, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting training and validation loss over iterations:\n",
    "if train:\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(solver.train_loss_history, \"o\")\n",
    "    plt.title(\"Train Loss\")\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(solver.val_loss_history, \"-o\")\n",
    "    plt.title(\"Val Loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a model from the saved state that produced\n",
    "# the lowest validation loss during training:\n",
    "\n",
    "# Requires the model classes be loaded\n",
    "\n",
    "# Assumes the model uses models.CoSADUV_NoTemporal architecture.\n",
    "# If not, this method will fail\n",
    "def load_model_from_checkpoint(model_name):\n",
    "    #filename = \"C:/Users/simon/Downloads/Project Models/\" + model_name + \".pth\"  # Run on own computer\n",
    "    filename = \"trained_models/\" + model_name + \".pth\"  # Run on NCC/Linux\n",
    "    if torch.cuda.is_available():\n",
    "        checkpoint = torch.load(filename)\n",
    "    else:\n",
    "        # Load GPU model on CPU\n",
    "        checkpoint = torch.load(filename, map_location=\"cpu\")\n",
    "    start_epoch = checkpoint[\"epoch\"]\n",
    "    best_accuracy = checkpoint[\"best_accuracy\"]\n",
    "    \n",
    "    if \"DSCLRCN\" in model_name:\n",
    "        model = DSCLRCN(input_dim=img_size, local_feats_net=\"Seg\")\n",
    "    elif \"CoSADUV_NoTemporal\" in model_name:\n",
    "        model = CoSADUV_NoTemporal(input_dim=img_size, local_feats_net=\"Seg\")\n",
    "    elif \"CoSADUV\" in model_name:\n",
    "        model = CoSADUV(input_dim=img_size, local_feats_net=\"Seg\")\n",
    "    else:\n",
    "        print(\"Error: no model name found in filename: {}\".format(model_name))\n",
    "        return\n",
    "    # Ignore extra parameters ('.num_batches_tracked'\n",
    "    # that are added on NCC due to different pytorch version)\n",
    "    model.load_state_dict(\n",
    "        checkpoint[\"state_dict\"], strict=False\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        \"=> loaded model checkpoint '{}' (trained for {} epochs)\\n   with architecture {}\".format(\n",
    "            model_name, checkpoint[\"epoch\"], type(model).__name__\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        print(\"   loaded to cuda\")\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_model(model_name):\n",
    "    #model = torch.load(\"C:/Users/simon/Downloads/Project Models/\" + model_name, map_location=\"cpu\")  # run on own computer\n",
    "    model = torch.load(\"trained_models/\" + model_name, map_location=\"cpu\")  # run on ncc/linux\n",
    "    print(\"=> loaded model '{}'\".format(model_name))\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        print(\"   loaded to cuda\")\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Loading some pretrained models to test them on the images:\n",
    "if train:\n",
    "    # Keep the trained model\n",
    "    while len(models) > 1:\n",
    "        del models[1]\n",
    "    model_names = [model_names[0]]\n",
    "    models = [models[0]]\n",
    "else:\n",
    "    while len(models) > 0:\n",
    "        del models[0]\n",
    "    model_names = []\n",
    "    models = []\n",
    "    \n",
    "# TODO\n",
    "# CoSADUV_NoTemporal on UAV123 with DoM loss func, Adam 1e-2 lr\n",
    "# CoSADUV_NoTemporal on UAV123 with NSS loss func, Adam 1e-2 lr\n",
    "# Above, plus transfer learning on EyeTrackUAV, same settings\n",
    "\n",
    "# TEST ALL MODELS (QUANTITATIVE with CE_MAE, DoM, NSS_alt (split into +ve and -ve images))\n",
    "# COLLECT SOME QUALITATIVE RESULTS FROM best DSCLRCN, CoSADUV_NoTemporal, CoSADUV models\n",
    "# Also collect some qualitative results of arbitrary good/bad results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DSCLRCN, UAV123, DoM loss func - Old Context\n",
    "# model_names.append(\"DSCLRCN/UAV123/Homebrew 3.58last 2.56best testing/model_DSCLRCN_homebrew_batch20_epoch5\")\n",
    "\n",
    "# DSCLRCN models\n",
    "## Trained on SALICON\n",
    "### NSS_loss\n",
    "# model_names.append(\"DSCLRCN/SALICON NSS -1.62NSS val best and last/best_model_DSCLRCN_NSS_loss_batch20_epoch5\")\n",
    "## Trained on UAV123\n",
    "### NSS_alt loss func\n",
    "# model_names.append(\"DSCLRCN/UAV123 NSS_alt 1.38last 3.15best testing/best_model_DSCLRCN_NSS_alt_batch20_epoch5\")\n",
    "\n",
    "\n",
    "# CoSADUV_NoTemporal models\n",
    "## Trained on UAV123\n",
    "### DoM loss func\n",
    "model_names.append(\"CoSADUV_NoTemporal/DoM SGD 0.01lr - 3.16 NSS_alt/best_model_CoSADUV_NoTemporal_DoM_batch20_epoch6\")\n",
    "### NSS_alt loss func\n",
    "# model_names.append(\"CoSADUV_NoTemporal/NSS_alt Adam lr 1e-4 - 1.36/best_model_CoSADUV_NoTemporal_NSS_alt_batch20_epoch5\")\n",
    "### CE_MAE loss func\n",
    "# model_names.append(\"CoSADUV_NoTemporal/best_model_CoSADUV_NoTemporal_CE_MAE_loss_batch20_epoch10\")\n",
    "\n",
    "\n",
    "# CoSADUV models (CoSADUV2)\n",
    "## Trained on UAV123\n",
    "### NSS_alt loss func\n",
    "#### 1 Frame backpropagation\n",
    "#### Kernel size 1\n",
    "# model_names.append(\"CoSADUV/NSS_alt Adam 0.001lr 1frame backprop size1 kernel -2train -0.7val 1epoch/best_model_CoSADUV_NSS_alt_batch20_epoch5\")\n",
    "#### Kernel size 3\n",
    "# model_names.append(\"CoSADUV/NSS_alt Adam 0.01lr 1frame backprop size3 kernel/best_model_CoSADUV_NSS_alt_batch20_epoch5\")\n",
    "#### 2 Frame backpropagation\n",
    "#### Kernel size 3\n",
    "# model_names.append(\"CoSADUV/NSS_alt Adam 0.01lr 2frame backprop size3 kernel - 6.56 NSS_alt val/best_model_CoSADUV_NSS_alt_batch20_epoch5\")\n",
    "### DoM loss func\n",
    "# Only very poor results achieved\n",
    "### CE_MAE loss func\n",
    "# Only very poor results achieved\n",
    "\n",
    "# CoSADUV_NoTemporal models with transfer learning on EyeTrackUAV\n",
    "# model_names.append(\"best_model_CoSADUV_NoTemporal_DoM_batch20_epoch5\")\n",
    "# model_names.append(\"best_model_CoSADUV_NoTemporal_NSS_alt_batch20_epoch5\")\n",
    "\n",
    "max_name_len = max([len(name) for name in model_names])\n",
    "# Load the models specified above\n",
    "iterable = model_names[1:] if train else model_names\n",
    "\n",
    "for i, name in enumerate(iterable):\n",
    "    if \"best_model\" in name:\n",
    "        models.append(load_model_from_checkpoint(name))\n",
    "    else:\n",
    "        models.append(load_model(name))\n",
    "\n",
    "print()\n",
    "print(\"Loaded all specified models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the different models on a random image from the val set:\n",
    "\n",
    "# Choose which two models to test\n",
    "m_index_1 = 0\n",
    "m_index_2 = 0\n",
    "\n",
    "# Pick a random test image and validation image\n",
    "test_video_id = 2 #test_video_id = randrange(0, len(test_loader))\n",
    "val_video_id = 7 #val_video_id  = randrange(0, len(val_loader))\n",
    "test_frame_id = 48 #test_frame_id = randrange(0, len(test_loader.__getitem__(test_video_id)))\n",
    "val_frame_id = 95 #val_frame_id  = randrange(0, len(val_loader.__getitem__(val_video_id)))\n",
    "\n",
    "print(\"Test video index: {}, val video index: {}\".format(test_video_id, val_video_id))    \n",
    "print(\"Test frame index: {}, val frame index: {}\".format(test_frame_id, val_frame_id))\n",
    "\n",
    "\n",
    "# Load the images\n",
    "for i, data in enumerate(test_loader.__getitem__(test_video_id)):\n",
    "    if i == test_frame_id//minibatchsize:\n",
    "        x, y = data\n",
    "        x = x[test_frame_id % minibatchsize]\n",
    "        y = y[test_frame_id % minibatchsize]\n",
    "        break\n",
    "for i, data in enumerate(val_loader.__getitem__(val_video_id)):\n",
    "    if i == val_frame_id//minibatchsize:\n",
    "        x_val, y_val = data\n",
    "        x_val = x_val[val_frame_id % minibatchsize]\n",
    "        y_val = y_val[val_frame_id % minibatchsize]\n",
    "        break\n",
    "\n",
    "\n",
    "# Get the original (before pre-processing) images to be displayed\n",
    "original = x.transpose(0,1).transpose(1,2) + torch.from_numpy(mean_image)\n",
    "original_val = x_val.transpose(0,1).transpose(1,2) + torch.from_numpy(mean_image)\n",
    "\n",
    "# Create copies of the images to pass through each model\n",
    "x = x.contiguous().view(1, *x.size())\n",
    "x_2 = x[:]\n",
    "x_val = x_val.contiguous().view(1, *x_val.size())\n",
    "x_2_val = x_val[:]\n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    x_val = x_val.cuda()\n",
    "    x_2 = x_2.cuda()\n",
    "    x_2_val = x_2_val.cuda()\n",
    "y = y.numpy()\n",
    "y_val = y_val.numpy()\n",
    "\n",
    "\n",
    "\n",
    "##### First model #####\n",
    "\n",
    "x_sal = models[m_index_1](Variable(x))\n",
    "if torch.cuda.is_available():\n",
    "    x_sal = x_sal.cpu()\n",
    "x_sal_nmp = x_sal.squeeze().data.numpy()\n",
    "\n",
    "# If model is temporal, reset the stored state\n",
    "if models[m_index_1].temporal:\n",
    "    models[m_index_1].clear_temporal_state()\n",
    "    models[m_index_1].detach_temporal_state()\n",
    "\n",
    "x_val_sal = models[m_index_1](Variable(x_val))\n",
    "if torch.cuda.is_available():\n",
    "    x_val_sal = x_val_sal.cpu()\n",
    "x_val_sal_nmp = x_val_sal.squeeze().data.numpy()\n",
    "\n",
    "if m_index_2 != m_index_1:\n",
    "    ##### Second model #####\n",
    "    x_2_sal = models[m_index_2](Variable(x_2))\n",
    "    if torch.cuda.is_available():\n",
    "        x_2_sal = x_2_sal.cpu()\n",
    "    x_2_sal_nmp = x_2_sal.squeeze().data.numpy()\n",
    "\n",
    "    if models[m_index_2].temporal:\n",
    "        models[m_index_2].clear_temporal_state()\n",
    "        models[m_index_2].detach_temporal_state()\n",
    "\n",
    "    x_2_val_sal = models[m_index_2](Variable(x_2_val))\n",
    "    if torch.cuda.is_available():\n",
    "        x_2_val_sal = x_2_val_sal.cpu()\n",
    "    x_2_val_sal_nmp = x_2_val_sal.squeeze().data.numpy()\n",
    "\n",
    "    \n",
    "# Normalise the output to [0, 1] range\n",
    "# x_val_sal_nmp -= x_val_sal_nmp.min()\n",
    "# x_val_sal_nmp /= x_val_sal_nmp.max()\n",
    "# x_sal_nmp -= x_sal_nmp.min()\n",
    "# x_sal_nmp /= x_sal_nmp.max()\n",
    "\n",
    "# Plot the output\n",
    "plt.figure(figsize=(24,16))\n",
    "\n",
    "##### Testing set image #####\n",
    "plt.subplot(3,4,1); plt.title('Original')\n",
    "plt.imshow(original, vmin=0, vmax=1)\n",
    "plt.subplot(3,4,2); plt.title('Ground Truth')\n",
    "plt.imshow(y, cmap='gray', vmin=0, vmax=1)\n",
    "\n",
    "# First model\n",
    "plt.subplot(3,4,3)\n",
    "plt.imshow(x_sal_nmp, cmap='gray', vmin=0, vmax=1); plt.title(model_names[m_index_1])\n",
    "# Second model\n",
    "if m_index_2 != m_index_1:\n",
    "    plt.subplot(3,4,4)\n",
    "    plt.imshow(x_2_sal_nmp, cmap='gray', vmin=0, vmax=1); plt.title(model_names[m_index_2])\n",
    "\n",
    "##### Validation set image #####\n",
    "plt.subplot(3,4,5); plt.title('Original Val')\n",
    "plt.imshow(original_val, vmin=0, vmax=1)\n",
    "plt.subplot(3,4,6); plt.title('Ground Truth Val')\n",
    "plt.imshow(y_val, cmap='gray', vmin=0, vmax=1)\n",
    "\n",
    "\n",
    "# First model\n",
    "plt.subplot(3,4,7)\n",
    "plt.imshow(x_val_sal_nmp, cmap='gray', vmin=0, vmax=1); plt.title(model_names[m_index_1])\n",
    "# Second model\n",
    "if m_index_2 != m_index_1:\n",
    "    plt.subplot(3,4,8)\n",
    "    plt.imshow(x_2_val_sal_nmp, cmap='gray', vmin=0, vmax=1); plt.title(model_names[m_index_2])\n",
    "    \n",
    "# Get the test_loss_func score of the val images\n",
    "print(model_names[m_index_1])\n",
    "x_val_sal_torch = torch.from_numpy(x_val_sal_nmp).unsqueeze(0)\n",
    "x_sal_torch = torch.from_numpy(x_sal_nmp).unsqueeze(0)\n",
    "y_val_torch = torch.from_numpy(y_val).unsqueeze(0)\n",
    "y_torch = torch.from_numpy(y).unsqueeze(0)\n",
    "\n",
    "\n",
    "print(\"[{}] NSS_loss Test:\".format(m_index_1), loss_functions.NSS_loss(x_sal_torch, y_torch).item())\n",
    "print(\"[{}] CE_MAE   Test:\".format(m_index_1), loss_functions.CE_MAE_loss(x_sal_torch, y_torch).item())\n",
    "print(\"[{}] CE       Test:\".format(m_index_1), loss_functions.CE_loss(x_sal_torch, y_torch).item())\n",
    "print(\"[{}] MAE      Test:\".format(m_index_1), loss_functions.MAE_loss(x_sal_torch, y_torch).item())\n",
    "print(\"[{}] DoM      Test:\".format(m_index_1), loss_functions.DoM(x_sal_torch, y_torch).item())\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"[{}] NSS_loss Validation:\".format(m_index_1), loss_functions.NSS_loss(x_val_sal_torch, y_val_torch).item())\n",
    "print(\"[{}] CE_MAE   Validation:\".format(m_index_1), loss_functions.CE_MAE_loss(x_val_sal_torch, y_val_torch).item())\n",
    "print(\"[{}] CE       Validation:\".format(m_index_1), loss_functions.CE_loss(x_val_sal_torch, y_val_torch).item())\n",
    "print(\"[{}] MAE      Validation:\".format(m_index_1), loss_functions.MAE_loss(x_val_sal_torch, y_val_torch).item())\n",
    "print(\"[{}] DoM      Validation:\".format(m_index_1), loss_functions.DoM(x_val_sal_torch, y_val_torch).item())\n",
    "\n",
    "if m_index_2 != m_index_1:\n",
    "    print(model_names[m_index_2])\n",
    "    x_2_val_sal_torch = torch.from_numpy(x_2_val_sal_nmp).unsqueeze(0)\n",
    "    print(\"[{}] CE_MAE Validation:\".format(m_index_2), loss_functions.CE_MAE_loss(x_2_val_sal_torch, y_val_torch).item())\n",
    "    print(\"[{}] CE Validation:\".format(m_index_2), loss_functions.CE_loss(x_2_val_sal_torch, y_val_torch).item())\n",
    "    print(\"[{}] MAE Validation:\".format(m_index_2), loss_functions.MAE_loss(x_2_val_sal_torch, y_val_torch).item())\n",
    "    print(\"[{}] NSS_loss Validation:\".format(m_index_2), loss_functions.NSS_loss(x_2_val_sal_torch, y_val_torch).item())\n",
    "    print(\"[{}] DoM Validation:\".format(m_index_2), loss_functions.DoM(x_2_val_sal_torch, y_val_torch).item())\n",
    "    print(\"[{}] NSS_alt Validation:\".format(m_index_2), loss_functions.NSS_alt(x_2_val_sal_torch, y_val_torch).item())\n",
    "    \n",
    "##### Heat map of GT and prediction on Validation set image (first model) #####\n",
    "heat_map = original_val.cpu().data.numpy()\n",
    "gt = y_val\n",
    "pred = x_val_sal_nmp[:]\n",
    "# Normalize pred so it's in range 0->1\n",
    "pred /= np.max(pred)\n",
    "\n",
    "alpha = 0.5\n",
    "heat_map = np.array([[[alpha*r, alpha*g, alpha*b] for [r, g, b] in row] for row in heat_map])\n",
    "gt       = np.array([[[(1-alpha)*x, 0, 0] for x in row] for row in gt])\n",
    "pred     = np.array([[[0, 0, (1-alpha)*x] for x in row] for row in pred])\n",
    "\n",
    "heat_map = heat_map + gt + pred\n",
    "\n",
    "plt.subplot(3, 4, 11)\n",
    "plt.imshow(heat_map, vmin=0, vmax=1); plt.title('Heat map 1st model: gt=red, pred=blue')\n",
    "\n",
    "if m_index_1 != m_index_2:\n",
    "    ##### Heat map of GT and prediction on Validation set image (second model) #####\n",
    "    heat_map = original_val.cpu().data.numpy()\n",
    "    gt = y_val\n",
    "    pred_2 = x_2_val_sal_nmp\n",
    "    # Normalize pred so it's in range 0->1\n",
    "    pred_2 /= np.max(pred_2)\n",
    "\n",
    "    alpha = 0.5\n",
    "    heat_map_2 = np.array([[[alpha*r, alpha*g, alpha*b] for [r, g, b] in row] for row in heat_map])\n",
    "    gt       = np.array([[[(1-alpha)*x, 0, 0] for x in row] for row in gt])\n",
    "    pred_2     = np.array([[[0, 0, (1-alpha)*x] for x in row] for row in pred_2])\n",
    "\n",
    "    heat_map_2 = heat_map_2 + gt + pred_2\n",
    "\n",
    "    plt.subplot(3, 4, 12)\n",
    "    plt.imshow(heat_map_2, vmin=0, vmax=1); plt.title('Heat map 2nd model: gt=red, pred=blue')\n",
    "\n",
    "# plt.savefig('ResExamples/example_test_'+str(test_image_id)+'_val_'+str(val_image_id)+'.png')\n",
    "plt.show()\n",
    "\n",
    "if models[m_index_1].temporal:\n",
    "    models[m_index_1].clear_temporal_state()\n",
    "    models[m_index_1].detach_temporal_state()\n",
    "if m_index_1 != m_index_2 and models[m_index_2].temporal:\n",
    "    models[m_index_2].clear_temporal_state()\n",
    "    models[m_index_2].detach_temporal_state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"C:/Users/simon/Downloads/Project Models/Results Data/CoSADUV_NoTemporal_NSS_alt_artefact.jpg\", x_sal_nmp*255)\n",
    "\n",
    "\n",
    "cv2.imwrite(\"C:/Users/simon/Downloads/Project Models/Results Data/CoSADUV_NoTemporal_NSS_alt_artefact.jpg\", x_val_sal_nmp*255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imwrite(\"/tmp/pbqk24_tmp/image0.jpg\", x_val_sal_nmp*255)\n",
    "cv2.imwrite(\"C:/Users/simon/Downloads/Project Models/Results Data/Input_image_1.jpg\", cv2.cvtColor(original.data.numpy()*255, cv2.COLOR_BGR2RGB))\n",
    "cv2.imwrite(\"C:/Users/simon/Downloads/Project Models/Results Data/GT_1.jpg\", y*255)\n",
    "\n",
    "\n",
    "cv2.imwrite(\"C:/Users/simon/Downloads/Project Models/Results Data/Input_image_2.jpg\", cv2.cvtColor(original_val.data.numpy()*255, cv2.COLOR_BGR2RGB))\n",
    "cv2.imwrite(\"C:/Users/simon/Downloads/Project Models/Results Data/GT_2.jpg\", y_val*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the different models on a random image from the val set:\n",
    "\n",
    "# Choose which two models to test\n",
    "m_index_1 = 0\n",
    "m_index_2 = 0\n",
    "\n",
    "# Pick a random test image and validation image\n",
    "test_video_id = 16 #test_video_id = randrange(0, len(test_loader))\n",
    "val_video_id = 11 #val_video_id  = randrange(0, len(val_loader))\n",
    "test_frame_id = 48 #test_frame_id = randrange(0, len(test_loader.__getitem__(test_video_id)))\n",
    "val_frame_id = 95 #val_frame_id  = randrange(0, len(val_loader.__getitem__(val_video_id)))\n",
    "\n",
    "print(\"Test video index: {}, val video index: {}\".format(test_video_id, val_video_id))    \n",
    "print(\"Test frame index: {}, val frame index: {}\".format(test_frame_id, val_frame_id))\n",
    "\n",
    "# Load specific images to use as examples\n",
    "\n",
    "# Load the images\n",
    "for i, data in enumerate(test_loader.__getitem__(test_video_id)):\n",
    "    print(i)\n",
    "    x, y = data\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "    x = x[0].contiguous().view(1, *x[0].size())\n",
    "    y = y[0].contiguous().view(1, *y[0].size())\n",
    "    x_sal = models[m_index_1](Variable(x))\n",
    "    if i == test_frame_id:\n",
    "        break\n",
    "    \n",
    "# If model is temporal, reset the stored state\n",
    "if models[m_index_1].temporal:\n",
    "    models[m_index_1].clear_temporal_state()\n",
    "    models[m_index_1].detach_temporal_state()\n",
    "    \n",
    "for i, data in enumerate(val_loader.__getitem__(val_video_id)):\n",
    "    print(i)\n",
    "    x_val, y_val = data\n",
    "    if torch.cuda.is_available():\n",
    "        x_val = x_val.cuda()\n",
    "        y_val = y_val.cuda()\n",
    "    x_val = x_val[0].contiguous().view(1, *x_val[0].size())\n",
    "    y_val = y_val[0].contiguous().view(1, *y_val[0].size())\n",
    "    x_val_sal = models[m_index_1](Variable(x_val))\n",
    "    if i % 10 == 0:\n",
    "        out = x_val_sal.squeeze().cpu().data.numpy()\n",
    "        out -= out.min()\n",
    "        out /= out.max()\n",
    "        x_val = x_val.cpu()\n",
    "        cv2.imwrite(\"/tmp/pbqk24_tmp/Person_Example (person7, frame95)/CoSADUV_NoTemporal_DoM_video_frame{}.jpg\".format(i), out*255)\n",
    "    if i == val_frame_id:\n",
    "        break\n",
    "\n",
    "# Get the original (before pre-processing) images to be displayed\n",
    "original = x.cpu().squeeze().transpose(0,1).transpose(1,2) + torch.from_numpy(mean_image)\n",
    "original_val = x_val.cpu().squeeze().transpose(0,1).transpose(1,2) + torch.from_numpy(mean_image)\n",
    "\n",
    "# Create copies of the images to pass through each model\n",
    "x = x.contiguous().view(1, *x.size())\n",
    "x_2 = x[:]\n",
    "x_val = x_val.contiguous().view(1, *x_val.size())\n",
    "x_2_val = x_val[:]\n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    x_val = x_val.cuda()\n",
    "    x_2 = x_2.cuda()\n",
    "    x_2_val = x_2_val.cuda()\n",
    "y = y.squeeze().cpu().numpy()\n",
    "y_val = y_val.squeeze().cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "##### First model #####\n",
    "\n",
    "# x_sal = models[m_index_1](Variable(x))\n",
    "if torch.cuda.is_available():\n",
    "    x_sal = x_sal.cpu()\n",
    "x_sal_nmp = x_sal.squeeze().data.numpy()\n",
    "\n",
    "# If model is temporal, reset the stored state\n",
    "if models[m_index_1].temporal:\n",
    "    models[m_index_1].clear_temporal_state()\n",
    "    models[m_index_1].detach_temporal_state()\n",
    "\n",
    "# x_val_sal = models[m_index_1](Variable(x_val))\n",
    "if torch.cuda.is_available():\n",
    "    x_val_sal = x_val_sal.cpu()\n",
    "x_val_sal_nmp = x_val_sal.squeeze().data.numpy()\n",
    "\n",
    "if m_index_2 != m_index_1:\n",
    "    ##### Second model #####\n",
    "    x_2_sal = models[m_index_2](Variable(x_2))\n",
    "    if torch.cuda.is_available():\n",
    "        x_2_sal = x_2_sal.cpu()\n",
    "    x_2_sal_nmp = x_2_sal.squeeze().data.numpy()\n",
    "\n",
    "    if models[m_index_2].temporal:\n",
    "        models[m_index_2].clear_temporal_state()\n",
    "        models[m_index_2].detach_temporal_state()\n",
    "\n",
    "    x_2_val_sal = models[m_index_2](Variable(x_2_val))\n",
    "    if torch.cuda.is_available():\n",
    "        x_2_val_sal = x_2_val_sal.cpu()\n",
    "    x_2_val_sal_nmp = x_2_val_sal.squeeze().data.numpy()\n",
    "\n",
    "# Normalise the output to [0, 1] range\n",
    "x_val_sal_nmp -= x_val_sal_nmp.min()\n",
    "x_val_sal_nmp /= x_val_sal_nmp.max()\n",
    "x_sal_nmp -= x_sal_nmp.min()\n",
    "x_sal_nmp /= x_sal_nmp.max()\n",
    "\n",
    "# Plot the output\n",
    "plt.figure(figsize=(24,16))\n",
    "\n",
    "# ##### Testing set image #####\n",
    "plt.subplot(3,4,1); plt.title('Original')\n",
    "plt.imshow(original, vmin=0, vmax=1)\n",
    "plt.subplot(3,4,2); plt.title('Ground Truth')\n",
    "plt.imshow(y, cmap='gray', vmin=0, vmax=1)\n",
    "\n",
    "# # First model\n",
    "plt.subplot(3,4,3)\n",
    "plt.imshow(x_sal_nmp, cmap='gray', vmin=0, vmax=1); plt.title(model_names[m_index_1])\n",
    "# Second model\n",
    "if m_index_2 != m_index_1:\n",
    "    plt.subplot(3,4,4)\n",
    "    plt.imshow(x_2_sal_nmp, cmap='gray', vmin=0, vmax=1); plt.title(model_names[m_index_2])\n",
    "\n",
    "##### Validation set image #####\n",
    "plt.subplot(3,4,5); plt.title('Original Val')\n",
    "plt.imshow(original_val, vmin=0, vmax=1)\n",
    "plt.subplot(3,4,6); plt.title('Ground Truth Val')\n",
    "plt.imshow(y_val, cmap='gray', vmin=0, vmax=1)\n",
    "\n",
    "\n",
    "# First model\n",
    "plt.subplot(3,4,7)\n",
    "plt.imshow(x_val_sal_nmp, cmap='gray', vmin=0, vmax=1); plt.title(model_names[m_index_1])\n",
    "# Second model\n",
    "if m_index_2 != m_index_1:\n",
    "    plt.subplot(3,4,8)\n",
    "    plt.imshow(x_2_val_sal_nmp, cmap='gray', vmin=0, vmax=1); plt.title(model_names[m_index_2])\n",
    "    \n",
    "# Get the test_loss_func score of the val images\n",
    "print(model_names[m_index_1])\n",
    "x_val_sal_torch = torch.from_numpy(x_val_sal_nmp).unsqueeze(0)\n",
    "x_sal_torch = torch.from_numpy(x_sal_nmp).unsqueeze(0)\n",
    "y_val_torch = torch.from_numpy(y_val).unsqueeze(0)\n",
    "y_torch = torch.from_numpy(y).unsqueeze(0)\n",
    "\n",
    "\n",
    "print(\"[{}] NSS_loss Test:\".format(m_index_1), loss_functions.NSS_loss(x_sal_torch, y_torch).item())\n",
    "print(\"[{}] CE_MAE   Test:\".format(m_index_1), loss_functions.CE_MAE_loss(x_sal_torch, y_torch).item())\n",
    "print(\"[{}] CE       Test:\".format(m_index_1), loss_functions.CE_loss(x_sal_torch, y_torch).item())\n",
    "print(\"[{}] MAE      Test:\".format(m_index_1), loss_functions.MAE_loss(x_sal_torch, y_torch).item())\n",
    "print(\"[{}] DoM      Test:\".format(m_index_1), loss_functions.DoM(x_sal_torch, y_torch).item())\n",
    "\n",
    "print()\n",
    "\n",
    "# print(\"[{}] Validation:\".format(m_index_1), test_loss_func(x_val_sal_torch, y_val_torch).item())\n",
    "print(\"[{}] NSS_loss Validation:\".format(m_index_1), loss_functions.NSS_loss(x_val_sal_torch, y_val_torch).item())\n",
    "print(\"[{}] CE_MAE   Validation:\".format(m_index_1), loss_functions.CE_MAE_loss(x_val_sal_torch, y_val_torch).item())\n",
    "print(\"[{}] CE       Validation:\".format(m_index_1), loss_functions.CE_loss(x_val_sal_torch, y_val_torch).item())\n",
    "print(\"[{}] MAE      Validation:\".format(m_index_1), loss_functions.MAE_loss(x_val_sal_torch, y_val_torch).item())\n",
    "print(\"[{}] DoM      Validation:\".format(m_index_1), loss_functions.DoM(x_val_sal_torch, y_val_torch).item())\n",
    "#print(\"[{}] NSS_alt Validation:\".format(m_index_1), loss_functions.NSS_alt(x_val_sal_torch, y_val_torch).item())\n",
    "\n",
    "if m_index_2 != m_index_1:\n",
    "    print(model_names[m_index_2])\n",
    "    x_2_val_sal_torch = torch.from_numpy(x_2_val_sal_nmp).unsqueeze(0)\n",
    "    print(\"[{}] CE_MAE Validation:\".format(m_index_2), loss_functions.CE_MAE_loss(x_2_val_sal_torch, y_val_torch).item())\n",
    "    print(\"[{}] CE Validation:\".format(m_index_2), loss_functions.CE_loss(x_2_val_sal_torch, y_val_torch).item())\n",
    "    print(\"[{}] MAE Validation:\".format(m_index_2), loss_functions.MAE_loss(x_2_val_sal_torch, y_val_torch).item())\n",
    "    print(\"[{}] NSS_loss Validation:\".format(m_index_2), loss_functions.NSS_loss(x_2_val_sal_torch, y_val_torch).item())\n",
    "    print(\"[{}] DoM Validation:\".format(m_index_2), loss_functions.DoM(x_2_val_sal_torch, y_val_torch).item())\n",
    "    print(\"[{}] NSS_alt Validation:\".format(m_index_2), loss_functions.NSS_alt(x_2_val_sal_torch, y_val_torch).item())\n",
    "    \n",
    "##### Heat map of GT and prediction on Validation set image (first model) #####\n",
    "heat_map = original_val.cpu().data.numpy()\n",
    "gt = y_val\n",
    "pred = x_val_sal_nmp[:]\n",
    "# Normalize pred so it's in range 0->1\n",
    "pred /= np.max(pred)\n",
    "\n",
    "alpha = 0.5\n",
    "heat_map = np.array([[[alpha*r, alpha*g, alpha*b] for [r, g, b] in row] for row in heat_map])\n",
    "gt       = np.array([[[(1-alpha)*x, 0, 0] for x in row] for row in gt])\n",
    "pred     = np.array([[[0, 0, (1-alpha)*x] for x in row] for row in pred])\n",
    "\n",
    "heat_map = heat_map + gt + pred\n",
    "\n",
    "plt.subplot(3, 4, 11)\n",
    "plt.imshow(heat_map, vmin=0, vmax=1); plt.title('Heat map 1st model: gt=red, pred=blue')\n",
    "\n",
    "if m_index_1 != m_index_2:\n",
    "    ##### Heat map of GT and prediction on Validation set image (second model) #####\n",
    "    heat_map = original_val.cpu().data.numpy()\n",
    "    gt = y_val\n",
    "    pred_2 = x_2_val_sal_nmp\n",
    "    # Normalize pred so it's in range 0->1\n",
    "    pred_2 /= np.max(pred_2)\n",
    "\n",
    "    alpha = 0.5\n",
    "    heat_map_2 = np.array([[[alpha*r, alpha*g, alpha*b] for [r, g, b] in row] for row in heat_map])\n",
    "    gt       = np.array([[[(1-alpha)*x, 0, 0] for x in row] for row in gt])\n",
    "    pred_2     = np.array([[[0, 0, (1-alpha)*x] for x in row] for row in pred_2])\n",
    "\n",
    "    heat_map_2 = heat_map_2 + gt + pred_2\n",
    "\n",
    "    plt.subplot(3, 4, 12)\n",
    "    plt.imshow(heat_map_2, vmin=0, vmax=1); plt.title('Heat map 2nd model: gt=red, pred=blue')\n",
    "\n",
    "# plt.savefig('ResExamples/example_test_'+str(test_image_id)+'_val_'+str(val_image_id)+'.png')\n",
    "plt.show()\n",
    "\n",
    "if models[m_index_1].temporal:\n",
    "    models[m_index_1].clear_temporal_state()\n",
    "    models[m_index_1].detach_temporal_state()\n",
    "if m_index_1 != m_index_2 and models[m_index_2].temporal:\n",
    "    models[m_index_2].clear_temporal_state()\n",
    "    models[m_index_2].detach_temporal_state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"/tmp/pbqk24_tmp/Boat_Example (wakeboard8, frame48)/CoSADUV_1bp_1k_video.jpg\", x_sal_nmp*255)\n",
    "\n",
    "\n",
    "cv2.imwrite(\"/tmp/pbqk24_tmp/Person_Example (person7, frame95)/CoSADUV_1bp_1k_video.jpg\", x_val_sal_nmp*255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"/tmp/pbqk24_tmp/image0.jpg\", x_val_sal_nmp*255)\n",
    "# cv2.imwrite(\"/tmp/pbqk24_tmp/image0.jpg\", cv2.cvtColor(original.data.numpy()*255, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for testing a model\n",
    "# Output is resized to the size of the data_source\n",
    "def test_model(model, data_loader, loss_fns=[loss_functions.MAE_loss]):\n",
    "    loss_sums = []\n",
    "    loss_counts = []\n",
    "    for i, loss_fn in enumerate(loss_fns):\n",
    "        if loss_fn != loss_functions.NSS_alt:\n",
    "            loss_sums.append(0)\n",
    "            loss_counts.append(0)\n",
    "        else:\n",
    "            loss_sums.append([0, 0])\n",
    "            loss_counts.append([0, 0])\n",
    "    for video_loader in tqdm(data_loader):\n",
    "        # Reset temporal state if model is temporal\n",
    "        if model.temporal:\n",
    "            model.clear_temporal_state()\n",
    "        for data in tqdm(video_loader):\n",
    "            inputs, labels = data\n",
    "            if torch.cuda.is_available():\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            # Produce the output\n",
    "            outputs = model(inputs).squeeze(1)\n",
    "            # if model is temporal detach its state\n",
    "            if model.temporal:\n",
    "                model.detach_temporal_state()\n",
    "            # Move the output to the CPU so we can process it using numpy\n",
    "            outputs = outputs.cpu().data.numpy()\n",
    "\n",
    "            # If outputs contains a single image, insert\n",
    "            # a singleton batchsize dimension at index 0\n",
    "            if len(outputs.shape) == 2:\n",
    "                outputs = np.expand_dims(outputs, 0)\n",
    "\n",
    "            # Resize the images to input size\n",
    "            outputs = np.array(\n",
    "                [\n",
    "                    cv2.resize(output, (labels.shape[2], labels.shape[1]))\n",
    "                    for output in outputs\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            outputs = torch.from_numpy(outputs)\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                outputs = outputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "            # Apply each loss function, add results to corresponding entry in loss_sums and loss_counts\n",
    "            for i, loss_fn in enumerate(loss_fns):\n",
    "                # If loss fn is NSS_alt, manually add std_dev() if the target is all-0\n",
    "                if loss_fn == loss_functions.NSS_alt:\n",
    "                    for i in range(len(labels)):\n",
    "                        if labels[i].sum() == 0:\n",
    "                            loss_sums[i][1] += outputs[i].std().item()\n",
    "                            loss_counts[i][1] += 1\n",
    "                        else:\n",
    "                            loss_sums[i][0] += loss_fn(outputs[i], labels[i]).item()\n",
    "                            loss_counts[i][0] += 1\n",
    "                else:\n",
    "                    loss_sums[i] += loss_fn(outputs, labels).item()\n",
    "                    loss_counts[i] += 1\n",
    "\n",
    "    return loss_sums, loss_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fns = [loss_functions.NSS_alt, loss_functions.CE_MAE_loss, loss_functions.CE_loss, loss_functions.MAE_loss, loss_functions.DoM]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Obtaining loss values on the test set for different models:\n",
    "for i, model_name in enumerate(tqdm(model_names)):\n",
    "    tqdm.write(\"model name: {}\".format(model_name))\n",
    "    if \"best_model\" in model_name:\n",
    "        model = load_model_from_checkpoint(model_name)\n",
    "    else:\n",
    "        model = load_model(model_name)\n",
    "\n",
    "    test_losses, test_counts = test_model(model, val_loader, loss_fns=loss_fns)\n",
    "\n",
    "    # Print out the result\n",
    "    \n",
    "    tqdm.write(\"[{}] Model: \".format(i, model_names[i]))\n",
    "\n",
    "    for i, func in enumerate(loss_fns):\n",
    "        if func == loss_functions.NSS_alt:\n",
    "            tqdm.write(\n",
    "                (\"{:25} : {:6f}\").format(\n",
    "                    'NSS_alt (+ve imgs)', test_losses[i][0] / test_counts[i][0]\n",
    "                )\n",
    "            )\n",
    "            tqdm.write(\n",
    "                (\"{:25} : {:6f}\").format(\n",
    "                    'NSS_alt (-ve imgs)', test_losses[i][1] / test_counts[i][1]\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            tqdm.write(\n",
    "                (\"{:25} : {:6f}\").format(\n",
    "                    func.__name__, test_losses[i] / test_counts[i]\n",
    "                )\n",
    "            )\n",
    "    del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
