{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from random import randint\n",
    "import sys\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.data_utils import get_SALICON_datasets\n",
    "from util.data_utils import get_direct_datasets\n",
    "\n",
    "# train_data, val_data, test_data, mean_image = get_SALICON_datasets('Dataset/Transformed') # 128x96\n",
    "dataset_root_dir = 'Dataset/Raw_Dataset'\n",
    "mean_image_name = 'mean_image.npy'\n",
    "img_size = (480, 640) # height, width - original: 480, 640, reimplementation: 96, 128\n",
    "train_data, val_data, test_data, mean_image = get_direct_datasets(dataset_root_dir, mean_image_name, img_size)\n",
    "\n",
    "from util.loss_functions import NSS_loss, NSS_loss_2, PCCLoss_torch\n",
    "\n",
    "models = []\n",
    "model_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train = False\n",
    "from models.DSCLRCN_PyTorch import DSCLRCN\n",
    "from util.solver import Solver\n",
    "\n",
    "batchsize = 20 # Recommended: 20. Determines how many images are processed before backpropagation is done\n",
    "minibatchsize = 2 # Recommended: 2 for 480x640. Determines how many images are processed in parallel on the GPU at once\n",
    "epoch_number = 10 # Recommended: 10 (epoch_number =~ batchsize/2)\n",
    "optim_str = 'SGD' # 'SGD' or 'Adam' Recommended: Adam\n",
    "optim_args = {'lr': 1e-2} # 1e-2 if SGD, 1e-4 if Adam\n",
    "loss_func = NSS_loss # NSS_loss or torch.nn.KLDivLoss() Recommended: NSS_loss\n",
    "\n",
    "if batchsize % minibatchsize:\n",
    "    print(\"Error, batchsize % minibatchsize must equal 0 ({} % {} != 0).\".format(batchsize, minibatchsize))\n",
    "num_minibatches = batchsize/minibatchsize\n",
    "optim_args['lr'] /= num_minibatches # Scale the lr down as smaller minibatches are used\n",
    "\n",
    "    optim = torch.optim.SGD if optim_str == 'SGD' else torch.optim.Adam\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=minibatchsize, shuffle=True, num_workers=8, pin_memory=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=minibatchsize, shuffle=True, num_workers=8, pin_memory=True)\n",
    "\n",
    "    if train:\n",
    "        # Attempt to train a model using the original image sizes\n",
    "        model = DSCLRCN(input_dim=img_size, local_feats_net='Seg')\n",
    "        # Set solver as torch.optim.SGD and lr as 1e-2, or torch.optim.Adam and lr 1e-4\n",
    "        solver = Solver(optim=optim, optim_args=optim_args, loss_func=loss_func, location='jupyter')\n",
    "        solver.train(model, train_loader, val_loader, num_epochs=epoch_number, num_minibatches=num_minibatches, log_nth=50, \n",
    "            filename_args={'batchsize' : batchsize, 'epoch_number' : epoch_number, 'optim' : optim_str}\n",
    "        )\n",
    "\n",
    "        models.append(model)\n",
    "        model_names.append('model_{}_lr2_batch{}_epoch{}'.format(optim_str, batchsize, epoch_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model:\n",
    "if train:\n",
    "    model.save('trained_models/model_{}_lr2_batch{}_epoch{}'.format(optim_str, batchsize, epoch_number))\n",
    "    with open('trained_models/solver_{}_lr2_batch{}_epoch{}.pkl'.format(optim_str, batchsize, epoch_number), 'wb') as outf:\n",
    "        pickle.dump(solver, outf, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting training and validation loss over iterations:\n",
    "if train:\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(solver.train_loss_history, 'o')\n",
    "    plt.title('Train Loss')\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(solver.val_loss_history, '-o')\n",
    "    plt.title('Val Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a model from the saved state that produced the lowest validation loss during training:\n",
    "\n",
    "from models.DSCLRCN_PyTorch import DSCLRCN # Requires the model class be loaded\n",
    "\n",
    "# Assumes the model uses models.DSCLRCN_PyTorch2 architecture. If not, this method will fail\n",
    "def load_model_from_checkpoint(model_name):\n",
    "    filename = \"trained_models/\" + model_name + \".pth\"\n",
    "    if torch.cuda.is_available():\n",
    "        checkpoint = torch.load(filename)\n",
    "    else:\n",
    "        # Load GPU model on CPU\n",
    "        checkpoint = torch.load(filename, map_location='cpu')\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    best_accuracy = checkpoint['best_accuracy']\n",
    "    \n",
    "    model = DSCLRCN(input_dim=img_size, local_feats_net='Seg')\n",
    "    model.load_state_dict(checkpoint['state_dict'], strict=False) # Ignore extra parameters ('.num_batches_tracked' that are added on NCC due to different pytorch version)\n",
    "\n",
    "            \n",
    "    print(\"=> loaded model checkpoint '{}' (trained for {} epochs)\".format(model_name, checkpoint['epoch']))\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "    return model\n",
    "\n",
    "def load_model(model_name):\n",
    "    model = torch.load(\"trained_models/\" + model_name, map_location='cpu')\n",
    "    print(\"=> loaded model_1 '{}'\".format(model_name))\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Loading some pretrained models to test them on the images:\n",
    "if train:\n",
    "    model_names = [model_names[0]]\n",
    "    models = [models[0]]\n",
    "else:\n",
    "    model_names = []\n",
    "    models = []\n",
    "\n",
    "# This model's best checkpoint\n",
    "model_names.append('best_model_SGD_lr2_batch20_epoch10')\n",
    "\n",
    "# model_0: The best model thusfar\n",
    "# model_names.append('model_SGD_lr2_batch20_epoch10')\n",
    "\n",
    "# model_1: Best contender for model_0\n",
    "# model_names.append('best_model_SGD_lr2_batch20_epoch10')\n",
    "\n",
    "# model_2 and on: Others\n",
    "\n",
    "\n",
    "\n",
    "# other models\n",
    "\n",
    "max_name_len = max([len(name) for name in model_names])\n",
    "# Load the models specified above\n",
    "iterable = model_names[1:] if train else model_names\n",
    "\n",
    "for i, name in enumerate(iterable):\n",
    "    if \"best_model\" in name:\n",
    "        models.append(load_model_from_checkpoint(name))\n",
    "    else:\n",
    "        models.append(load_model(name))\n",
    "\n",
    "print()\n",
    "print(\"Loaded all specified models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the different models on a random image from the val set:\n",
    "\n",
    "# Choose which two models to test\n",
    "m_index_1 = 0\n",
    "m_index_2 = 0\n",
    "\n",
    "# Pick a random test image and validation image\n",
    "test_image_id = randint(0, len(test_data)-1)\n",
    "val_image_id  = randint(0, len(val_data)-1)\n",
    "print(\"Test image: {}, Val image: {}\".format(test_image_id, val_image_id))\n",
    "\n",
    "# Load the images\n",
    "x,y = test_data.__getitem__(test_image_id)\n",
    "x_val, y_val = val_data.__getitem__(val_image_id)\n",
    "\n",
    "# Get the original (before pre-processing) images to be displayed\n",
    "original = x.transpose(0,1).transpose(1,2) + torch.from_numpy(mean_image)\n",
    "original_val = x_val.transpose(0,1).transpose(1,2) + torch.from_numpy(mean_image)\n",
    "\n",
    "# Create copies of the images to pass through each model\n",
    "x = x.contiguous().view(1, *x.size())\n",
    "x_2 = x[:]\n",
    "x_val = x_val.contiguous().view(1, *x_val.size())\n",
    "x_2_val = x_val[:]\n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    x_val = x_val.cuda()\n",
    "    x_2 = x_2.cuda()\n",
    "    x_2_val = x_2_val.cuda()\n",
    "y = y.numpy()\n",
    "y_val = y_val.numpy()\n",
    "\n",
    "\n",
    "\n",
    "##### First model #####\n",
    "\n",
    "x_sal = models[m_index_1](Variable(x))\n",
    "if torch.cuda.is_available():\n",
    "    x_sal = x_sal.cpu()\n",
    "x_sal_nmp = x_sal.squeeze().data.numpy()\n",
    "# Blur the saliency map\n",
    "\n",
    "# Sigma value used by all models, as all inputs are of same shape\n",
    "sigma = 0.035*min(x_sal_nmp.shape) # Define a sigma to be used for Gaussian blurring\n",
    "kernel_size = int(4*sigma)\n",
    "kernel_size += 1 if kernel_size % 2 == 0 else 0 # Make sure the kernel size is odd\n",
    "\n",
    "x_sal_nmp = cv2.GaussianBlur(x_sal_nmp, (kernel_size, kernel_size), sigma)\n",
    "\n",
    "x_val_sal = models[m_index_1](Variable(x_val))\n",
    "if torch.cuda.is_available():\n",
    "    x_val_sal = x_val_sal.cpu()\n",
    "x_val_sal_nmp = x_val_sal.squeeze().data.numpy()\n",
    "# Blur the saliency map\n",
    "# x_val_sal_nmp = cv2.GaussianBlur(x_val_sal_nmp, (kernel_size, kernel_size), sigma)\n",
    "\n",
    "if m_index_2 != m_index_1:\n",
    "    ##### Second model #####\n",
    "    x_2_sal = models[m_index_2](Variable(x_2))\n",
    "    if torch.cuda.is_available():\n",
    "        x_2_sal = x_2_sal.cpu()\n",
    "    x_2_sal_nmp = x_2_sal.squeeze().data.numpy()\n",
    "    # Blur the saliency map\n",
    "    x_2_sal_nmp = cv2.GaussianBlur(x_2_sal_nmp, (kernel_size, kernel_size), sigma)\n",
    "\n",
    "\n",
    "    x_2_val_sal = models[m_index_2](Variable(x_2_val))\n",
    "    if torch.cuda.is_available():\n",
    "        x_2_val_sal = x_2_val_sal.cpu()\n",
    "    x_2_val_sal_nmp = x_2_val_sal.squeeze().data.numpy()\n",
    "    # Blur the saliency map\n",
    "    x_2_val_sal_nmp = cv2.GaussianBlur(x_2_val_sal_nmp, (kernel_size, kernel_size), sigma)\n",
    "\n",
    "\n",
    "# Plot the output\n",
    "plt.figure(figsize=(24,16))\n",
    "\n",
    "##### Testing set image #####\n",
    "plt.subplot(3,4,1); plt.title('Original')\n",
    "plt.imshow(original, vmin=0, vmax=1)\n",
    "plt.subplot(3,4,2); plt.title('Ground Truth')\n",
    "plt.imshow(y, cmap='gray', vmin=0, vmax=1)\n",
    "\n",
    "# First model\n",
    "plt.subplot(3,4,3)\n",
    "plt.imshow(x_sal_nmp, cmap='gray'); plt.title(model_names[m_index_1])\n",
    "# Second model\n",
    "if m_index_2 != m_index_1:\n",
    "    plt.subplot(3,4,4)\n",
    "    plt.imshow(x_2_sal_nmp, cmap='gray'); plt.title(model_names[m_index_2])\n",
    "\n",
    "##### Validation set image #####\n",
    "plt.subplot(3,4,5); plt.title('Original Val')\n",
    "plt.imshow(original_val, vmin=0, vmax=1)\n",
    "plt.subplot(3,4,6); plt.title('Ground Truth Val')\n",
    "plt.imshow(y_val, cmap='gray', vmin=0, vmax=1)\n",
    "\n",
    "# First model\n",
    "plt.subplot(3,4,7)\n",
    "plt.imshow(x_val_sal_nmp, cmap='gray'); plt.title(model_names[m_index_1])\n",
    "# Second model\n",
    "if m_index_2 != m_index_1:\n",
    "    plt.subplot(3,4,8)\n",
    "    plt.imshow(x_2_val_sal_nmp, cmap='gray'); plt.title(model_names[m_index_2])\n",
    "    \n",
    "# Get the NSS score of the val images\n",
    "print(\"[{}] Validation:\".format(m_index_1), NSS_loss(x_val_sal_nmp, y_val))\n",
    "if m_index_2 != m_index_1:\n",
    "    print(model_names[m_index_2])\n",
    "    print(\"[{}] Validation:\".format(m_index_2), NSS_loss(x_2_val_sal_nmp, y_val))\n",
    "    \n",
    "##### Heat map of GT and prediction on Validation set image (first model) #####\n",
    "heat_map = original_val.cpu().data.numpy()\n",
    "gt = y_val\n",
    "pred = x_val_sal_nmp\n",
    "# Normalize pred so it's in range 0->1\n",
    "pred /= np.max(pred)\n",
    "\n",
    "alpha = 0.2\n",
    "heat_map = np.array([[[alpha*r, alpha*g, alpha*b] for [r, g, b] in row] for row in heat_map])\n",
    "gt       = np.array([[[(1-alpha)*x, 0, 0]   for x         in row] for row in gt])\n",
    "pred     = np.array([[[0, 0, (1-alpha)*x]   for x         in row] for row in pred])\n",
    "\n",
    "heat_map = heat_map + gt + pred\n",
    "\n",
    "plt.subplot(3, 4, 10)\n",
    "plt.imshow(heat_map, vmin=0, vmax=1); plt.title('Heat map: gt=red, pred=blue')\n",
    "\n",
    "# plt.savefig('ResExamples/example_test_'+str(test_image_id)+'_val_'+str(val_image_id)+'.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for testing a model\n",
    "# Output is resized to the size of the data_source\n",
    "def test_model(model, data_source, loss_fn=NSS_loss):\n",
    "    test_loader = torch.utils.data.DataLoader(data_source, batch_size=minibatchsize, shuffle=True, num_workers=8)\n",
    "    loss_sum = 0\n",
    "    \n",
    "    for data in tqdm(test_loader):\n",
    "        inputs, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        # Produce the output\n",
    "        outputs = model(inputs).squeeze(1)\n",
    "        # Move the output to the CPU so we can process it using numpy\n",
    "        outputs = outputs.cpu().data.numpy()\n",
    "        \n",
    "        # If outputs contains a single image, make it shape (1, x, y) instead of (x, y)\n",
    "        if len(outputs.shape) == 2:\n",
    "            outputs = np.expand_dims(outputs, 0)\n",
    "\n",
    "        # Resize the images to input size\n",
    "        outputs = np.array([cv2.resize(output, (labels.shape[2], labels.shape[1])) for output in outputs])\n",
    "\n",
    "        # Apply a Gaussian filter to blur the saliency maps\n",
    "        sigma = 0.035*min(labels.shape[1], labels.shape[2])\n",
    "        kernel_size = int(4*sigma)\n",
    "        # make sure the kernel size is odd\n",
    "        kernel_size += 1 if kernel_size % 2 == 0 else 0\n",
    "        \n",
    "        outputs = np.array([cv2.GaussianBlur(output, (kernel_size, kernel_size), sigma) for output in outputs])\n",
    "        \n",
    "        outputs = torch.from_numpy(outputs)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            outputs = outputs.cuda()\n",
    "            labels  = labels.cuda()\n",
    "        \n",
    "        loss_sum += loss_fn(outputs, labels).item()\n",
    "        \n",
    "    return loss_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Obtaining NSS Loss values on the test set for different models:\n",
    "loss_fn = NSS_loss_2\n",
    "\n",
    "# Create new validation dataset with different size\n",
    "# img_size_2 = (480, 640) # height, width - original: 480, 640, reimplementation: 96, 128\n",
    "# _, val_data_2, _ = get_direct_datasets(dataset_root_dir, mean_image_name, img_size_2)\n",
    "\n",
    "# test on validation data as we don't have ground truths for the test data (this was also done in original DSCLRCN paper)\n",
    "\n",
    "test_losses = []\n",
    "for model in tqdm(models):\n",
    "    test_losses.append(test_model(model, val_data, loss_fn=loss_fn))\n",
    "\n",
    "# Print out the result\n",
    "print('Normalized Scanpath Saliency on Validation set:')\n",
    "\n",
    "for i, loss in enumerate(test_losses):\n",
    "    print(('[{}] {:' + str(max_name_len) + '} : {:6f}').format(i, model_names[i], -1*np.sum(loss)/len(val_data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
