{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from random import randint\n",
    "import sys\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.data_utils import get_SALICON_datasets\n",
    "# from util.data_utils import get_raw_SALICON_datasets\n",
    "\n",
    "train_data, val_data, test_data, mean_image = get_SALICON_datasets('Dataset/Transformed') # 128x96\n",
    "#train_data, val_data, test_data, mean_image = get_raw_SALICON_datasets(dataset_folder='/tmp/pbqk24_tmp') # 640x480\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NSS_loss(x, y):\n",
    "        \"\"\"\n",
    "        Computes the Normalized Scanpath Saliency between x (output of a model)\n",
    "        and y (label). X and Y are assumed to be torch tensors.\n",
    "        \"\"\"\n",
    "        # Normalize x\n",
    "        x = (x - x.mean())/x.std()\n",
    "        # Create a binary mask to select values from x where the corresponding y value is > 0\n",
    "        mask = y > 0 #Use threshold=0 always\n",
    "        scanpath = torch.masked_select(x, mask)\n",
    "        # return negative mean, as loss is minimized in training\n",
    "        return -scanpath.mean()\n",
    "\n",
    "def NSS_loss_alt(x, y):\n",
    "        \"\"\"\n",
    "        Computes the Normalized Scanpath Saliency between x (output of a model)\n",
    "        and y (label). x and y are assumed to be torch tensors.\n",
    "        \"\"\"\n",
    "        # Normalize x\n",
    "        x = (x - x.mean())/x.std()\n",
    "        \n",
    "        # Compute the element-wise multiplication of x and y\n",
    "        scanpath = x * y\n",
    "        \n",
    "        # Compute the sum of the scanpath divided by the sum of values in y as NSS\n",
    "        nss = scanpath.sum()/y.sum()\n",
    "        \n",
    "        # NSS loss = -NSS\n",
    "        return -nss\n",
    "\n",
    "def PCCLoss_torch(x, y):\n",
    "    \"\"\"Computes Pearson Cross Correlation loss\n",
    "    :param x: prediction\n",
    "    :param y: label\n",
    "    \"\"\"\n",
    "    vx = x - torch.mean(x)\n",
    "    vy = y - torch.mean(y)\n",
    "    \n",
    "    cc = torch.sum(vx*y) / (torch.sqrt(torch.sum(vx ** 2)) * torch.sqrt(torch.sum(vy ** 2)))\n",
    "    \n",
    "    # since cc is in [-1, 1], and 0 is 'bad' and close to -1 or 1 is 'good', return the abs value of cc\n",
    "    cc = abs(cc)\n",
    "    # actually return 1 -  cc, as we need to return a loss (since 1 is good, we return loss as 1 - cc)\n",
    "    loss = 1 - cc\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from util.data_utils import OverfitSampler\n",
    "from models.DSCLRCN_PyTorch import DSCLRCN #DSCLRCN_PyTorch, DSCLRCN_PyTorch2 or DSCLRCN_PyTorch3\n",
    "from util.solver import Solver\n",
    "\n",
    "batchsize = 10 # Recommended: 20\n",
    "epoch_number = 10 # Recommended: 10 (epoch_number =~ batchsize/2)\n",
    "net_type = 'Seg' # 'Seg' or 'CNN' Recommended: Seg\n",
    "optim_str = 'SGD' # 'SGD' or 'Adam' Recommended: Adam\n",
    "optim_args = {'lr': 1e-2} # 1e-2 if SGD, 1e-4 if Adam\n",
    "loss_func = NSS_loss_alt # NSS_loss or torch.nn.KLDivLoss() Recommended: NSS_loss\n",
    "\n",
    "optim = torch.optim.SGD if optim_str == 'SGD' else torch.optim.Adam\n",
    "\n",
    "#num_train = 100\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batchsize, shuffle=True, num_workers=4, pin_memory=True)#,\n",
    "                                           #sampler=OverfitSampler(num_train))\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batchsize, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Attempt to train a model using the original image sizes\n",
    "model = DSCLRCN(input_dim=(96, 128), local_feats_net=net_type)\n",
    "# Set solver as torch.optim.SGD and lr as 1e-2, or torch.optim.Adam and lr 1e-4\n",
    "solver = Solver(optim=optim, optim_args=optim_args, loss_func=loss_func)\n",
    "solver.train(model, train_loader, val_loader, num_epochs=epoch_number, log_nth=50, filename_args={\n",
    "    'batchsize' : batchsize,'epoch_number' : epoch_number,\n",
    "    'net_type' : net_type, 'optim' : optim_str}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model:\n",
    "model.save('pretrained/model_{}_{}_lr4_batch{}_epoch{}_model1'.format(net_type, optim_str, batchsize, epoch_number))\n",
    "with open('pretrained/solver_{}_{}_lr4_batch{}_epoch{}_model1.pkl'.format(net_type, optim_str, batchsize, epoch_number), 'wb') as outf:\n",
    "    pickle.dump(solver, outf, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting training and validation loss over iterations:\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(solver.train_loss_history, 'o')\n",
    "plt.title('Train Loss')\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(solver.val_loss_history, '-o')\n",
    "plt.title('Val Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a model from the saved state that produced the lowest validation loss during training:\n",
    "\n",
    "from models.DSCLRCN_PyTorch import DSCLRCN # Requires the model class be loaded\n",
    "from models.DSCLRCN_PyTorch2 import DSCLRCN as DSCLRCN2 # The second alternative model class\n",
    "\n",
    "# Assumes the model uses models.DSCLRCN_PyTorch2 architecture. If not, this method will fail\n",
    "def load_model_from_checkpoint(model_name):\n",
    "    filename = \"trained_models/\" + model_name + \".pth\"\n",
    "    if torch.cuda.is_available():\n",
    "        checkpoint = torch.load(filename)\n",
    "    else:\n",
    "        # Load GPU model on CPU\n",
    "        checkpoint = torch.load(filename, map_location='cpu')\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    best_accuracy = checkpoint['best_accuracy']\n",
    "    # Find which local_feats_net the model used\n",
    "    if model_name.find('Seg') > -1:\n",
    "        model = DSCLRCN(input_dim=(96, 128), local_feats_net='Seg')\n",
    "    else:\n",
    "        model = DSCLRCN(input_dim=(96, 128), local_feats_net='CNN')\n",
    "    try:\n",
    "        model_class = 1\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "    except RuntimeError:\n",
    "        # The model was trained using the alternative model class\n",
    "        if model_name.find('Seg') > -1:\n",
    "            model = DSCLRCN2(input_dim=(96, 128), local_feats_net='Seg')\n",
    "        else:\n",
    "            model = DSCLRCN2(input_dim=(96, 128), local_feats_net='CNN')\n",
    "        model_class = 2\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "            \n",
    "    print(\"=> loaded model architecture {} checkpoint '{}' (trained for {} epochs)\".format(model_class, model_name, checkpoint['epoch']))\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "    return model\n",
    "\n",
    "def load_model(model_name):\n",
    "    model = torch.load(\"trained_models/\" + model_name, map_location='cpu')\n",
    "    print(\"=> loaded model_1 '{}'\".format(model_name))\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Loading some pretrained models to test them on the images:\n",
    "models = []\n",
    "model_names = []\n",
    "\n",
    "# model_0: The best performing checkpoint of the model trained during this execution cycle\n",
    "# model_names.append('best_model_{}_{}_lr4_batch{}_epoch{}'.format(net_type, optim_str, batchsize, epoch_number))\n",
    "model_names.append('b20 e10 KLDiv Adam (best vanilla)/model_Seg_100_lr4_batch20_epoch10')\n",
    "\n",
    "# model_1: Best model thusfar\n",
    "# Load the batchsize = 20, epoch = 10 model - best produced so far\n",
    "model_names.append(\"Model 1 NSS SGD (best faithful)/best_model_Seg_SGD_lr1_batch10_epoch10\")\n",
    "\n",
    "# model_2: Best contender for model_0\n",
    "# Uses SGD and Pearson's CC loss function (proper, loss taken as 1 - abs(cc))\n",
    "# model_names.append(\"b20 e20 PCC abs/best_model_Seg_SGD_lr4_batch20_epoch10\")\n",
    "# model_names.append('DSCLRCN Model 1/best_model_Seg_SGD_lr4_batch10_epoch10')\n",
    "\n",
    "\n",
    "# other models\n",
    "\n",
    "\n",
    "max_name_len = max([len(name) for name in model_names])\n",
    "# Load the models specified above\n",
    "for i, name in enumerate(model_names):\n",
    "    if \"best_model\" in name:\n",
    "        models.append(load_model_from_checkpoint(name))\n",
    "    else:\n",
    "        models.append(load_model(name))\n",
    "\n",
    "print()\n",
    "print(\"Loaded all specified models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the original images from the test set ('test_datadict.pickle': dictionary of images and fixation maps)\n",
    "# NOTE: This does NOT contain any fixation maps, as these are not provided with SALICON test images\n",
    "with open('Dataset/Transformed/test_datadict.pickle', 'rb') as f:\n",
    "        test_data_original = pickle.load(f)\n",
    "        print(\"Test data loaded\")\n",
    "\n",
    "# Loading the original images from the validation set ('val_datadict.pickle': dictionary of images and fixation maps)\n",
    "with open('Dataset/Transformed/val_datadict.pickle', 'rb') as f:\n",
    "        val_data_original = pickle.load(f)\n",
    "        print(\"Validation data loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the different models on a random image from the val set:\n",
    "\n",
    "# Pick a random test image and validation image\n",
    "test_image_id = randint(0, len(test_data_original['images'])-1)\n",
    "val_image_id  = randint(0, len(val_data_original['images'])-1)\n",
    "\n",
    "# Load the images\n",
    "x,y = test_data.__getitem__(test_image_id)\n",
    "x_val, y_val = val_data.__getitem__(val_image_id)\n",
    "\n",
    "# Get the original (before pre-processing) images to be displayed\n",
    "original = test_data_original['images'][test_image_id]\n",
    "original_val = val_data_original['images'][val_image_id]\n",
    "\n",
    "# Loading an individual/specific image stored in /Dataset\n",
    "# x = cv2.imread('Dataset/test.jpg').astype(np.float32)/255.; y = cv2.imread('Dataset/test_GT.jpg').astype(np.float32)/255. # Load the image and GT\n",
    "# x = cv2.cvtColor(x,cv2.COLOR_BGR2RGB); y = cv2.cvtColor(y, cv2.COLOR_BGR2RGB) # convert from BGR (cv2) to RGB (matplotlib)\n",
    "# x = cv2.resize(x,(128, 96), interpolation = cv2.INTER_AREA); y = cv2.resize(y,(128, 96), interpolation = cv2.INTER_AREA) # Resize images to 128, 96\n",
    "# original = x.copy() # copy the image to use as output\n",
    "\n",
    "# x -= mean_image # normalize x\n",
    "# x = x.transpose(2,0,1) # Convert from H, W, C to C, H, W (ordering used by PyTorch tensors)\n",
    "# x = torch.from_numpy(x) # Convert np arrays to tensors\n",
    "# y = torch.from_numpy(y)\n",
    "\n",
    "\n",
    "# Create copies of the images to pass through each model\n",
    "x = x.contiguous().view(1, *x.size())\n",
    "x_2 = x[:]\n",
    "x_val = x_val.contiguous().view(1, *x_val.size())\n",
    "x_2_val = x_val[:]\n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    x_val = x_val.cuda()\n",
    "    x_2 = x_2.cuda()\n",
    "    x_2_val = x_2_val.cuda()\n",
    "y = y.numpy()\n",
    "y_val = y_val.numpy()\n",
    "\n",
    "\n",
    "\n",
    "##### First model #####\n",
    "\n",
    "x_sal = models[0](Variable(x))\n",
    "if torch.cuda.is_available():\n",
    "    x_sal = x_sal.cpu()\n",
    "x_sal_nmp = x_sal.squeeze().data.numpy()\n",
    "\n",
    "\n",
    "# Sigma used by both/all models as all inputs same shape\n",
    "sigma = 0.035*min(x_sal_nmp.shape) # Define a sigma to be used for Gaussian blurring\n",
    "\n",
    "# Blur the saliency map\n",
    "\n",
    "# Sigma value used by all models, as all inputs are of same shape\n",
    "sigma = 0.035*min(x_sal_nmp.shape) # Define a sigma to be used for Gaussian blurring\n",
    "\n",
    "x_sal_nmp = cv2.GaussianBlur(x_sal_nmp, (int(4*sigma), int(4*sigma)), sigma)\n",
    "\n",
    "x_val_sal = models[0](Variable(x_val))\n",
    "if torch.cuda.is_available():\n",
    "    x_val_sal = x_val_sal.cpu()\n",
    "x_val_sal_nmp = x_val_sal.squeeze().data.numpy()\n",
    "# Blur the saliency map\n",
    "x_val_sal_nmp = cv2.GaussianBlur(x_val_sal_nmp, (int(4*sigma), int(4*sigma)), sigma)\n",
    "\n",
    "##### Second model #####\n",
    "x_2_sal = models[1](Variable(x_2))\n",
    "if torch.cuda.is_available():\n",
    "    x_2_sal = x_2_sal.cpu()\n",
    "x_2_sal_nmp = x_2_sal.squeeze().data.numpy()\n",
    "# Blur the saliency map\n",
    "x_2_sal_nmp = cv2.GaussianBlur(x_2_sal_nmp, (int(4*sigma), int(4*sigma)), sigma)\n",
    "\n",
    "\n",
    "x_2_val_sal = models[1](Variable(x_2_val))\n",
    "if torch.cuda.is_available():\n",
    "    x_2_val_sal = x_2_val_sal.cpu()\n",
    "x_2_val_sal_nmp = x_2_val_sal.squeeze().data.numpy()\n",
    "# Blur the saliency map\n",
    "x_2_val_sal_nmp = cv2.GaussianBlur(x_2_val_sal_nmp, (int(4*sigma), int(4*sigma)), sigma)\n",
    "\n",
    "\n",
    "# Plot the output\n",
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "##### Testing set image #####\n",
    "plt.subplot(2,4,1); plt.title('Original')\n",
    "plt.imshow(original, vmin=0, vmax=1)\n",
    "plt.subplot(2,4,2); plt.title('Ground Truth')\n",
    "plt.imshow(y, cmap='gray', vmin=0, vmax=1)\n",
    "\n",
    "# First model\n",
    "plt.subplot(2,4,3)\n",
    "plt.imshow(x_sal_nmp, cmap='gray', vmin=0, vmax=1); plt.title(model_names[0])\n",
    "# Second model\n",
    "plt.subplot(2,4,4)\n",
    "plt.imshow(x_2_sal_nmp, cmap='gray', vmin=0, vmax=1); plt.title(model_names[1])\n",
    "\n",
    "##### Validation set image #####\n",
    "plt.subplot(2,4,5); plt.title('Original Val')\n",
    "plt.imshow(original_val, vmin=0, vmax=1)\n",
    "plt.subplot(2,4,6); plt.title('Ground Truth Val')\n",
    "plt.imshow(y_val, cmap='gray', vmin=0, vmax=1)\n",
    "\n",
    "# First model\n",
    "plt.subplot(2,4,7)\n",
    "plt.imshow(x_val_sal_nmp, cmap='gray'); plt.title(model_names[0])\n",
    "# Second model\n",
    "plt.subplot(2,4,8)\n",
    "plt.imshow(x_2_val_sal_nmp, cmap='gray'); plt.title(model_names[1])\n",
    "\n",
    "# plt.savefig('ResExamples/example_test_'+str(test_image_id)+'_val_'+str(val_image_id)+'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_val_sal_nmp.min(), x_val_sal_nmp.max())\n",
    "test = x_val_sal_nmp/x_val_sal_nmp.max()\n",
    "print(test.min(), test.max())\n",
    "cv2.imshow(\"batch20_epoch10_val\", test)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Pearson Cross Correlation loss function, using numpy:\n",
    "def PCC_loss_numpy(x, y):\n",
    "    \"\"\"Computes Pearson Cross Correlation loss\n",
    "    :param x: prediction\n",
    "    :param y: label\n",
    "    \"\"\"\n",
    "    vx = x - np.mean(x)\n",
    "    vy = y - np.mean(y)\n",
    "    \n",
    "    loss = np.sum(vx*y) / (np.sqrt(np.sum(vx ** 2)) * np.sqrt(np.sum(vy ** 2)))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# Define the Normalized Scanpath Saliency loss function, using numpy:\n",
    "def NSS_loss_numpy(x, y):\n",
    "        \"\"\"\n",
    "        Computes the Normalized Scanpath Saliency between x (output of a model)\n",
    "        and y (label). X and Y are assumed to be torch tensors.\n",
    "        \"\"\"\n",
    "        # Normalize x\n",
    "        x = (x - x.mean())/x.std()\n",
    "        # Create a binary mask to select values from x where the corresponding y value is > 0\n",
    "        mask = y <= 0 #Use threshold=0 always, reversed as numpy function masks out True and keeps False\n",
    "        scanpath = np.ma.masked_array(x, mask)\n",
    "        # return negative mean, as loss is minimized in training\n",
    "        return -scanpath.mean()\n",
    "    \n",
    "# Define NSS function\n",
    "def NSS_numpy(x, y):\n",
    "    return -NSS_loss_numpy(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define a function for testing a model\n",
    "# The pipeline is different depending on if the loss fn is numpy or torch based (check naively implemented so far)\n",
    "# This is because the proper method of testing, applying a gaussian blur to the output map, has only been implemented to use numpy.\n",
    "# Thus, the torch peipeline will not yield correct results as it does not correctly follow the method of the original paper.\n",
    "def test_model(model, data_source, loss_fn=PCC_loss_numpy, input_size=(640, 480)):\n",
    "    test_loader = torch.utils.data.DataLoader(data_source, batch_size=5, shuffle=True, num_workers=4)\n",
    "    testLosses = []\n",
    "    \n",
    "    for data in tqdm(test_loader):\n",
    "        inputs, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = Variable(inputs.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs = Variable(inputs)\n",
    "            labels = Variable(labels)\n",
    "            \n",
    "        ### TORCH PIPELINE ###\n",
    "        if loss_fn == PCCLoss_torch:\n",
    "            # Produce the output\n",
    "            outputs = model(inputs).squeeze()\n",
    "\n",
    "            # Zero-center the fixation maps by dividing each value in each fixation map by the sum of all values in that\n",
    "            # fixation map\n",
    "            labels_sum = torch.sum(labels.contiguous().view(labels.size(0),-1), dim=1)\n",
    "            labels /= labels_sum.contiguous().view(*labels_sum.size(), 1, 1).expand_as(labels)\n",
    "        \n",
    "        ### NUMPY PIPELINE ###\n",
    "        #if loss_fn == PCCLoss_numpy:\n",
    "        else:\n",
    "            # Produce the output\n",
    "            outputs = model(inputs).squeeze()\n",
    "            # Move the output to the CPU so we can process it using numpy\n",
    "            outputs = outputs.cpu().data.numpy()\n",
    "            \n",
    "            # Show the input and output, side to side\n",
    "#             cv2.imshow(\"Input & Output\", cv2.cvtColor(np.hstack(((inputs.cpu().data.numpy()[0].transpose(1, 2, 0) + mean_image), np.repeat(outputs[0, :, :, np.newaxis], 3, axis=2))), cv2.COLOR_RGB2BGR))\n",
    "#             cv2.waitKey(0)\n",
    "            \n",
    "            # Resize the images to input size\n",
    "            outputs = np.array([cv2.resize(output, input_size) for output in outputs])\n",
    "            \n",
    "            # Apply a Gaussian filter to blur the saliency maps\n",
    "            sigma = 0.035*min(input_size[0], input_size[1])\n",
    "            outputs = np.array([cv2.GaussianBlur(output, (int(4*sigma), int(4*sigma)), sigma) for output in outputs])\n",
    "\n",
    "            # Zero-center the fixation maps by dividing each value in each fixation map by the sum of all values in that\n",
    "            # fixation map\n",
    "#             labels_sum = torch.sum(labels.contiguous().view(labels.size(0),-1), dim=1)\n",
    "#             labels /= labels_sum.contiguous().view(*labels_sum.size(), 1, 1).expand_as(labels)\n",
    "            \n",
    "            labels = labels.cpu().numpy()\n",
    "            # Show the blurred output and the GT, side to side\n",
    "#             cv2.imshow(\"Ground Truth & Blurred Output\", np.hstack((labels[0], outputs[0])))\n",
    "#             cv2.waitKey(0)\n",
    "        \n",
    "        ### BOTH PIPELINES ###\n",
    "        testLosses.append(loss_fn(outputs, labels).item())\n",
    "    \n",
    "    return testLosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining PCC Loss values on the test set for different models:\n",
    "\n",
    "# loss_fn = nn.KLDivLoss()\n",
    "# Use Pearson Cross Correlation loss\n",
    "loss_fn = NSS_numpy\n",
    "\n",
    "# test on validation data as we don't have ground truths for the test data (this was also done in original DSCLRCN paper)\n",
    "\n",
    "test_losses = []\n",
    "for model in tqdm(models):\n",
    "    test_losses.append(test_model(model, val_data, loss_fn=loss_fn, input_size=(128, 96)))\n",
    "\n",
    "# Print out the result\n",
    "if loss_fn == PCC_loss_numpy:\n",
    "    print('Pearson Cross Correlation Loss on Validation set:')\n",
    "elif loss_fn == NSS_loss_numpy:\n",
    "    print('Normalized Scanpath Saliency Loss on Validation set:')\n",
    "else:\n",
    "    print('Normalized Scanpath Saliency on Validation set:')\n",
    "\n",
    "for i, loss in enumerate(test_losses):\n",
    "    print(('[{}] {:' + str(max_name_len) + '} : {:6f}').format(i, model_names[i], np.mean(loss)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
